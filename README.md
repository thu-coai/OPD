![图片](https://lingyou-1302942961.cos.ap-beijing.myqcloud.com/lingyou/166747137310657482761-5415-450b-a792-701f66b87229.png)
------




<p align="center">
  <a href="https://lingyou-1302942961.cos.ap-beijing.myqcloud.com/lingyou/166753329455537e99a85-0d50-4a67-bc66-20ebaac526a2.PNG">Demo(微信公众号)</a> •
  <a href="http://coai.cs.tsinghua.edu.cn/static/opd/posts/opd_blog/">博客</a> •
  <a href="https://fatocijyic.feishu.cn/docx/MRW0duajYoeTB3xgOaPcsFOInnd">模型申请</a> 
</p>



# OPD：中文开放域对话预训练模型

OPD是一个中文开放域对话预训练模型，拥有63亿参数，在70GB高质量对话数据上进行训练而成。它具有如下优势：

- **大规模**：OPD的模型参数量为6.3B，是目前世界上规模最大的开源中文对话预训练模型

- **高性能**：我们通过自动评测和人工评测来全面评估OPD的性能。评测结果显示，OPD兼顾出色的闲聊能力与知识问答能力。得益于此，OPD的**多轮交互能力突出**，能够与用户进行多轮、深入的对话交互，性能显著优于EVA2.0, PLATO和PANGU-BOT，更受用户偏爱。

- **开源开放**：我们后续计划逐步开源**一系列中文对话模型相关生态**，推动中文对话领域的发展。具体包括：

  - **世界上最大的开源中文对话预训练模型**：OPD

  - **多维度中文对话评价模型**：[对话信息量](https://huggingface.co/thu-coai/roberta-zh-specific)、[相关性](https://huggingface.co/thu-coai/roberta-zh-sensible)、[一致性](https://huggingface.co/thu-coai/roberta-base-cdconv)、[安全性](https://huggingface.co/thu-coai/roberta-base-cold?text=%E6%88%91%E5%96%9C%E6%AC%A2%E4%BD%A0%E3%80%82+%E6%88%91%E7%88%B1%E4%BD%A0)等多个维度各自的评价模型。

![Alt Text](https://lingyou-1302942961.cos.ap-beijing.myqcloud.com/lingyou/1667550295655b055f894-2175-4b88-89ee-04b4b8cacbfb.gif)

![图片](https://lingyou-1302942961.cos.ap-beijing.myqcloud.com/lingyou/1667550036683b4d9d64c-b8d9-463d-b06b-35648a84f323.png)

## 性能

### 自动评测

我们构建了包含500条对话数据的高质量评测集，并首先在该评测集上进行了自动评测。OPD在BLEU-4和F1等自动指标上均能达到现有中文对话模型的最优性能，同时在多样性指标Distinct-3/4上也能达到与PLATO相近的性能。

![图片](https://lingyou-1302942961.cos.ap-beijing.myqcloud.com/lingyou/1667550074117dd526d29-3122-4f8c-8af9-125b04bc922f.png)

### 人工评测（静态）

我们进一步在包含500条对话数据的评测集上进行了静态人工评测。针对每条对话数据的输入信息，使所有模型都生成回复，每条回复由3位标注者在一致性、相关性、具体性上按照1-3分的尺度来进行打分。OPD在具体性上能够超过所有基线模型达到最优性能，在一致性和相关性上也能和最优的基线模型达到相似的性能。

然后我们进行了配对的静态人工评测，具体做法是针对每条对话数据的输入信息，由OPD和基线模型分别生成回复，然后由标注者挑选其中总体质量更高的回复。OPD在配对人工评测中能够优于所有基线模型，达到目前中文对话模型的最优性能。

![图片](https://lingyou-1302942961.cos.ap-beijing.myqcloud.com/lingyou/1667550111585c2a44aea-e69d-48a5-953c-de14791da16c.png)

### 人工评测（多轮交互）

我们还招募了15位标注者进行了多轮交互式人工评测。每位标注者需预先选定3个话题及对话开头，分别和各个中文对话模型进行对话，我们要求每次对话的轮数至少为16。标注者在交互后根据一致性、相关性和具体性三个维度按照1-5分的尺度进行打分，并按照总体质量对不同对话模型在同一个对话开头的表现进行偏好选择。交互式评测的结果和静态评测相似，OPD在具体性和总体质量上显著超过了所有基线模型，而在一致性和相关性上与最优基线模型表现相近。

![图片](https://lingyou-1302942961.cos.ap-beijing.myqcloud.com/lingyou/1667550148821ee0d26aa-d60d-4797-871b-cc95cd3763cc.png)

### 交互样例

![图片](https://lingyou-1302942961.cos.ap-beijing.myqcloud.com/lingyou/166754875054784293da6-dedd-4f14-a623-d4dca80a080d.png)

## 预训练

### 预训练数据集

OPD使用的数据均来自**公开可爬取、可访问**的数据源。我们在实验中发现，相比于通用预训练语言模型，对话预训练模型对于数据的质量更加敏感。因此，我们设计了严格、全面的数据清洗流程，最终筛选出70GB高质量对话数据用于OPD的预训练，清洗前后的数据留存比约10%。

### 模型架构

OPD采用UniLM架构，共包含6.3B参数，采用语言模型作为预训练任务。为保证OPD的多轮对话能力，我们将模型最大截断长度设为512。OPD在预训练阶段引入了soft prompt，以促进下游任务上参数高效的微调。更多细节将在后续发布的技术报告中说明。

## 未来工作

OPD目前仍处于“**初生**”状态，我们欢迎广大用户和研究人员加入OPD的社区，共同推进中文对话的发展。CoAI小组也将继续扎根中文对话领域，持续优化OPD。未来的发展方向如下：

- **从人类反馈中学习**：与人类交互是对话模型最自然的应用方式，我们也在交互实验中发现了当前版本OPD存在的一些缺陷。在部署OPD后，我们将根据human-bot的交互反馈，持续改进OPD的性能，并定期发布版本迭代，与中文对话社区分享我们最新的成果。
- **OPD的持续微调**：我们将通过持续微调的方式，赋予OPD新的下游技能（例如：情感安抚、知识检索），进一步提升OPD的表现。

## 贡献

### 前期准备

**模型架构设计与实现：**
温佳鑫

**预实验(收敛速度、稳定性)：**
温佳鑫

**预训练数据集构建：**
宋溢

**技术指导：**
柯沛，顾煜贤

### 模型训练

**大规模预训练：**
温佳鑫

### 后期工作

**模型评测(自动)：**
温佳鑫，万大振，宋溢

**模型评测(人工)：**
宋溢，魏文，温佳鑫

**模型服务部署(API，demo):**
宋溢，彭立彪，杨家铭

**对话评价模型：**
宋溢，郑楚杰，邓佳文

**博客写作：**
温佳鑫，柯沛

### 总项目周期

**学生负责人：**
温佳鑫

**项目总负责：**
黄民烈

## 致谢

感谢华为，OPPO提供的支持